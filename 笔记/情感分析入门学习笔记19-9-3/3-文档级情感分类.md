# 文档级情感分析

## 1.监督学习

### 1.1 评价分类器的性能指标

&emsp;&emsp;经常使用的评价指标有:精确率,召回率,F值

分类器在测试数据集上面预测正确或错误,有四种情况

- TP 将正类预测为了正类的数目
- FN 将正类预测为了负类的数目
- FP 将负类预测为了整类的数目
- TN 将负类预测为了负类的数目

精确率$P = \frac{TP}{TP + FP}$


召回率$R = \frac{TP}{TP + FN}$


F1值$F1 = \frac{2TP}{2TP+FP+FN}$

### 1.2 基于机器学习算法的情感分析

#### 1.2.1 已有的用于二分类问题的算法(将文本分为正面还是负面):

- 朴素贝叶斯分类器
- 支持向量机
- 最大熵分类器
......

采用的特征:
- 一元文法 unigram: 例如: 哈/尔/滨/工/业/大/学
- 二元文法 bigram: &ensp;例如: 哈尔/尔滨/滨工/工业/业大/大学
......

#### 1.2.2 情感分析的关键在于抽取有效的特征

一般可以从下面几个地方抽取有效的特征
 
 - 词和词频: 带有词频信息的n-gram和Unigram
 - 词性: 例如形容词之类的,可以用来表达一些情感和观点
 - 情感词和情感短语: 一些褒义词,贬义词之类的
 - 观点的规则: 在一些固定的文本结构或者语言成分中可能会隐含的表达一些观点
 - 情感转置词: 例如出现的否定句,否定词之类的
 - 句法依存关系: 不懂~~~

 ## 2.基于无监督的情感分类

 ### 2.1 使用句法模板和网络检索的情感分嗯嘞

 - 首先根据一些定义好的词性的模板在要分析的句子中寻找符合条件的两个连续的词
- 然后使用点互信息$PMI$来计算所抽取到的短语的情感倾向.
其中
$$PMI(word_1,word_2)=\log_2{\frac{P(word_1, word_2)}{P(word_1)P(word_2)}}$$.
$PMI$可以来体现两个词在统计上的依存程度.
- 然后使用$PMI$来计算短语的$SO$倾向,计算的过程其实很简单,就是让这个短语和正面情感词$excellent$和负面情感词$poor$之间的关联度来计算
$$
SO(phrase)=PMI(phrase, "excellent") - PMI(phrase, "poor")
$$
- 那怎么计算$PMI$呢,这里是直接把短语和正负面情感词提交给搜素引擎,对于每个搜素,搜素引擎就会把搜到的相关文档的数目(命中数)返回,当然这里最好是限制一下搜素的两个词之间的距离,原作者设置的是两个词最远不超过10个词,,那么公式改写成:
$$
SO(phrase)=\log_2{\frac{hits(phrase \ NEAR"excellent")hits("poor")}{hits(phrase \ NEAR"poor")hits("excellent")}}
$$
- 若$SO$值为正,那么就是褒义,否则就是贬义

### 2.2 使用情感词典的情感分类

- 在计算文档的情感倾向的时候,除了要考虑到情感词典中的单词,还要考虑到否点词,情感加强词
- 否定词例如not,这样的话就需要把情感词的分数$SO$取反
- 情感加强词,例如more, less等

## 3.情感评分预测

## 4.跨领域情感分类

## 5.跨语言情感分类

## 6.文档的情绪分类




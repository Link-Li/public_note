### 1.相对位置信息

这部分等看了论文Self-Attention with Relative Position Representations之后再准备补上

### 2.CNN本身就有位置信息

CNN本身就可以提取出来数据的一些位置信息，但是一般来说，CNN的网络中都会包含一些池化操作，这些池化操作对于图像来说具有很好的特征提取能力，可以保证特征的位置和旋转不变性，也就是说其目的是提取出来图像的重要特征，而不会考虑到位置信息。所以这就导致了池化层丢失了所有的位置信息，这对于NLP来说是灾难性的，因为文本中的位置信息非常重要。

一个解决办法就是采用K max Pooling，可以<a href='https://zhuanlan.zhihu.com/p/29925124' target='_blank'>参考这里</a>，其原理也比较简单，就是将max pooling改成了带有顺序的max pooling，其会抽取一个序列中的k个单元，按照从大到小的顺序，抽取出来k个单元，但是这些单元依旧按照顺序排列，这样就可以在一定程度上解决位置信息丢失的问题。不过实际上依旧会丢失位置信息，因为CNN的整个计算是在缩减整个序列的长度，最终缩减成一个特征向量，这样必定会导致位置的丢失，而k max pooling只是保留了部分位置信息，也没有保留所有的位置信息，所以即使对CNN加入位置信息，最终在计算的时候也会慢慢的丢失掉。